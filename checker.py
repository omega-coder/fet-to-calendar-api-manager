import argparse
import logging
import sys
from pprint import pprint

from fet_api_to_gcal import db
from fet_api_to_gcal.common.utils import (error_str, getDate, info_str,
                                          path_leaf, perror, psuccess,
                                          success_str, timestamped_filename)
from fet_api_to_gcal.models import Calendar, Resource, Std_mail, Teacher

# TODO: add proper logging to the script. (file + stdout).
# TODO: add an arguemt parser to script.

dates = {
    "2CPI": "2020/02/23",  # ! needs to be changed accordingly!
    "1CS": "2020/02/23",  # ! needs to be changed accordingly!
    "2CS": "2020/02/23",  # ! needs to be changed accordingly!
    "3CS": "2020/02/23",  # ! needs to be changed accordingly!
    "1CPI": "2020/02/23",  # ! needs to be changed accordingly!
}


def check_timetable_validity(timetable_path,
                             dates,
                             events_freq=1,
                             max_events=None):
    """Converts event form a FET csv generated timetable file to google calendar events, and checks if any erors are\
         present 
    
    Args:
        timetable_path (str): path to the timetable csv file generated by FET.
        dates (dict): a dictionary type key: value with keys corresppnding to the study years
                      and a value corresponding to the starting study date of that year.
                      IMPORTANT: the starting date must correspond the the first day of the week (Sunday)  
        events_freq (int, optional): frequency of the generated google events. Defaults to 1.
        max_events (int, optional): maximum number of gogole events to be generated.If None, then all
                                    the event in timetable_path will be generated. Defaults to None.
    
    Returns:
        list: list of google styled events, each google event is a python dictionary.
    """

    # SETUP LOGGING

    log_filename = timestamped_filename(filename=path_leaf(timetable_path))

    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',
        datefmt='%m-%d %H:%M:%S',
        filename="./logs/{}_checker_script.log".format(log_filename),
        filemode='w')

    console = logging.StreamHandler()
    console.setLevel(logging.WARNING)
    formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')
    console.setFormatter(formatter)
    logging.getLogger('').addHandler(console)
    logging.info(info_str("Started logging in file {}".format(log_filename)))

    timezone = "Africa/Algiers"
    try:
        f = open(timetable_path, "r")
    except Exception as e:
        logging.exception(
            error_str("Exception while opening file {}".format(
                path_leaf(timetable_path))))
    lines = f.readlines()[1::]
    all_events = []  # to hold all json gevents later!
    temp_dict_holder = {}
    for line in lines:
        line_splitted = list(
            map(lambda x: x.replace('"', ''),
                line.strip().split(",")))[:-1]
        if "Pause" not in line_splitted[2]:
            if line_splitted[0] not in list(temp_dict_holder.keys()):
                start_end = line_splitted[2].split("-")
                temp_dict_holder[line_splitted[0]] = {
                    "Day":
                    line_splitted[1],
                    "start":
                    start_end[0],
                    "end":
                    start_end[1],
                    "teachers":
                    line_splitted[5].split("+"),
                    "room":
                    line_splitted[-1].upper(),
                    "summary":
                    "{} {} {}".format(line_splitted[-2], line_splitted[-4],
                                      line_splitted[-3]),
                    "std_set":
                    line_splitted[3]
                }
            else:
                temp_dict_holder[
                    line_splitted[0]]["end"] = line_splitted[2].split("-")[1]
        else:
            # ? if pause in line record then ignore the line.
            # TODO: treat line records with Pause time as part of the event to prohibit reservations in Pause time
            continue

    # ? 2nd phase

    # ? indexes are used to allow non-ordered events to be generated successfully.
    logging.info(info_str("Started converting event to google events"))
    indexes = list(map(int, list(temp_dict_holder.keys())))
    for event_inx in indexes:
        try:
            event___old = temp_dict_holder[str(event_inx)]
        except KeyError as e:
            logging.exception(
                error_str(
                    "Exception in event at index {} thus will not be added".
                    format(event_inx)))
        __gevent__ = {"summary": event___old["summary"]}

        # ? get attendees emails
        __gevent__["attendees"] = []
        # teachers
        for teacher_name in event___old["teachers"]:
            teacher = Teacher.query.filter_by(fet_name=teacher_name).first()
            if teacher is not None:
                __gevent__["attendees"].append(
                    {"email": teacher.teacher_email})
            else:
                logging.warning(
                    error_str("Teacher {} not found (event index: {})".format(
                        teacher_name, event_inx)))

        # students (important part)
        if event___old["std_set"] == "":
            logging.error(
                error_str(
                    "Std_set empty in event index : {}, thus event is ignored".
                    format(event_inx)))
            continue

        for std_set__ in event___old["std_set"].split("+"):

            std_mails_obj = Std_mail.query.filter_by(std_set=std_set__).first()
            if std_mails_obj is not None:
                __gevent__["attendees"].append(
                    {"email": std_mails_obj.std_email})
            else:
                logging.error(
                    error_str(
                        "No Mapped email found for {}, thus calendar for it will be ignored"
                        .format(std_set__)))

        # add room if existing

        if event___old["room"] != "":
            res = Resource.query.filter_by(
                resource_name=event___old["room"]).first()
            if res is not None:
                __gevent__["attendees"].append({
                    "email": res.resource_email,
                    "resource": True
                })
            else:
                logging.warning(
                    error_str("Room {} not found in database".format(
                        event___old["room"])))
        else:
            logging.warning(
                error_str("Room at event index {} is empty".format(event_inx)))

        # ? recurrence rule
        __gevent__["recurrence"] = [
            "RRULE:FREQ=WEEKLY;COUNT=" + str(events_freq)
        ]
        dateTime_start = getDate(dates, event___old["std_set"].split(" ")[0],
                                 event___old["Day"],
                                 event___old["start"].split("h")[0],
                                 event___old["start"].split("h")[1])
        dateTime_end = getDate(dates, event___old["std_set"].split()[0],
                               event___old["Day"],
                               event___old["end"].split("h")[0],
                               event___old["end"].split("h")[1])
        __gevent__["start"] = {
            "timeZone": timezone,
            "dateTime": dateTime_start,
        }
        __gevent__["end"] = {
            "timeZone": timezone,
            "dateTime": dateTime_end,
        }
        all_events.append(__gevent__)

        if len(all_events) == max_events:
            logging.info(
                success_str(
                    "Converted {} events successfully (check log for warnings, if any)"
                    .format(max_events)))
            return all_events
    logging.info(
        success_str(
            "Converted {} events successfully (check log for warnings, if any)"
            .format(len(all_events))))
    return all_events


def check_google_event(gevent):
    """Checks if a google calendar object can be sent to the API without any errors/.\
        So, any errors would be either from the API itself or the network status.
    
    Args:
        gevent (dict): A google calendar event 
    
    Raises:
        NotImplementedError: Obviously, this is not yet implemented, daah!
    """
    raise NotImplementedError


if __name__ == "__main__":
    # ? create an arguemnt parser
    parser = argparse.ArgumentParser(
        description="Script to check FET timetable file for any errors/warnings before running the import" \
                    " operation from the web app")
    parser.add_argument("-f",
                        "--file",
                        type=str,
                        metavar='Path',
                        dest='file',
                        help="Path to the FET generated timetable CSV file.")

    # ? Parse arguments
    args = parser.parse_args()
    tt_path = args.file
    all_events = check_timetable_validity(timetable_path=tt_path, dates=dates)
    for event in all_events:
        resource = None
        teachers = []
        std_sets_emails = []
        if "resource" in event["attendees"][-1].keys():
            resource = event["attendees"][-1]
            event["attendees"].remove(resource)

        for ev_att in event["attendees"]:
            if Teacher.query.filter_by(teacher_email=ev_att["email"]).first():
                teachers.append(ev_att)
            else:
                std_sets_emails.append(ev_att)

        event["attendees"].clear()
        event["attendees"].extend(teachers)
        if resource is not None:
            event["attendees"].append(resource)

        for std_mail in std_sets_emails:
            cal_rec = Calendar.query.filter_by(
                std_email=std_mail["email"]).first()
            if cal_rec:
                calendar_id = cal_rec.calendar_id_google
            else:
                perror("Calendar does not exist, check please")
                continue
